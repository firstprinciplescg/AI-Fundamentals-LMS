# Manus overview (autonomy, risk labeling, sandboxing)

**Audience:** Founders, owners, and small-business executives  
**Prerequisites:** None

## What you’ll learn
- Contain autonomy to low-risk tasks
- Use explicit approvals for high-impact actions
- Run in a separate workspace with anonymized data

## Key topics we cover
- General-purpose autonomous agent concepts
- Sandbox-first execution and scopes
- Multi-step tasks with verification
- Operational risk labeling

## Executive overview
This lesson translates complex AI concepts into practical management decisions. We focus on how to evaluate opportunities, reduce risk, and move from pilot experiments to measurable, repeatable workflows. You’ll see what matters strategically, what can be delegated, and what to insist on when teams propose AI-enabled solutions.


## How it works (plain-English)
We keep the mechanics simple: inputs (your task, data, rules) go into a model or agent, the system reasons with tools and constraints, and then returns an output. When the task requires action—sending emails, updating a CRM, generating documents—an **automation layer** or **agent runtime** executes steps under guardrails (permissions, reviews, logs).

## Common pitfalls to avoid
- Allowing broad permissions by default
- No rollback; hard-to-audit actions

## What to measure
- Intervention rate, incident count, rollback success


## Next steps
Run the associated hands‑on exercise and capture baseline metrics this week. Bring at least one “keep/kill/iterate” decision to the next session.
